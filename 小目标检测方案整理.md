## 小目标检测方案整理

小目标检测是计算机视觉领域中的一个极具挑战性的问题。随着深度学习和计算机视觉的不断发展，越来越多的领域对小目标的检测需求越来越突出。



#### 1、定义

小目标检测：顾名思义，就是对相对目标来说较小的物体进行检测，可以是卫星地图中的船只，可以是照片中的小物件等；通过来说，小目标在图像中的尺寸小于 32 x 32 像素的物体。

在COCO数据集中，对目标进行了大中小的定义：

- 小目标：area < 32x32
- 中目标：32x32 < area < 96x96
- 大目标：area > 96x96

当然，对于不同的任务、场景，大小的定义也是不同的。



#### 2、意义

小目标检测的意义在于它可以提高技术的应用范围，同时可以帮助打架更好的理解图像中的细节。

其，在我们日常生活中有着广泛的应用，例如交通监控、医学影像分析、无人机航拍等：

- 交通监控：应用于信号灯、车牌检测等；
- 医学影像分析：应用于识别微小的肿瘤细胞等；
- 无人机航拍：应用于识别微小的障碍物，以弥补激光雷达难以探测的窘况；



#### 3、挑战

小目标检测的难度是可想而知的，小目标是相对于整体成像来说的，往往小目标在图中占比很小，下面举几个例子感受一下：

1. 室内监控，离监控位近的位置，人成像较大，检测效果好，但远离监控位的对角线区域，会相对差上很多，特别容易造成漏检和误检；
2. 室外监控，同样，人流量庞大，且距离较远的时候，就很容易出现漏检的情况；

![](./img/小目标图1.png)

如上图，在我们平时训练模型前进行标注数据时，通常绿色的框是我们经常会去进行标记的，但是那些个类似红色框中的目标，我们往往会放弃掉，因为他们像素占比过小，标了太多，容易造成训练曲线“抖动”，不标，那肯定就是造成很多漏检。



#### 4、解决方案

双阶段目标检测算法：由于存在ROI Pooling之类的操作，因此小目标的特征会被放大，其特征轮廓也更为清晰，因此检出率通常也会更高。

这里还是围绕较成熟的单阶段目标检测算法进行展开。

> **增大输入图像分辨率**

图像分辨率无疑是最关键的，如果同样视野范围的图像，若分辨率越高，那么其像素尺寸值就会越大，那么它的信息就会变多，在下采样过程多，信息保留的也就会越多。

因此将输入图像的分辨率提高，可以更好地捕捉目标的细节，可以提高小目标检测的准确性和召回率，从而更好地识别和跟踪目标物体。

> **增大模型输入尺寸**

就是对输入图像进行放大，再丢进模型训练。不过这会导致模型计算量的增加和速度的降低，这里需要自行考量利弊进行取舍，根据实际需求和可用资源进行调整，找到最佳的模型输入尺寸。

在推理时也可以视情况开启测试时增强Test Time Augmentation-TTA，特别是打比赛的时候。TTA是啥不知道。

- TTA：所谓TTA，思想非常简单，就是在评测阶段，给每个输入进行多种数据增广变换，将一个输入变成多个输入，然后再merge起来一起输出，形成一种ensemble的效果，一方面可以提点，另一方面可以提升model calibration （ECE来评价）的效果，实现起来也是非常简单，可以直接用Pretrained model来做，相当环保。 
- TTA：大概就是对测试集进行数据增强，扩充数据集，也就是在测试的时候，先增强图像，完了之后都去做预测，把预测结果在一块处理，得到这个图像的最终得分结果。（有种取巧的感觉）

> **特征融合**

**多尺度特征融合**

这个应该不陌生吧，看过yolo系列应该都知道。

由于小目标的尺寸较小，其特征信息往往分布在图像的多个尺度上，因此在多个尺度的特征图中进行融合，可提高模型对小目标的感知能力。常见的多尺度特征融合方法有：**Feature Pyramid Networks-FPN-特征晶字塔网络，Path Aggregation Networks-PAN-路径聚合网络**等。

**长跳跃连接**

将浅层特征和深层特征进行融合，以增强对小目标的定位能力。

- 浅层特征：细节信息丰富，语义信息较弱；
- 深层特征：细节信息匮乏，语义信息富饶；

**注意力机制**

注意力机制是一种能够将模型的注意力集中到重要区域的技术，可以通过**对特征图进行加权处理**，将更多的注意力集中到小目标所在的区域，从而提高对小目标的检测能力。常见的注意力机制包括`SENet`、`SKNet`等。 

> **数据增强**

使用数据增强，可提高模型的鲁棒性和泛化能力。对于小目标检测任务，可通过以下增强方式来提升：

**尺度变换**

对原始图像进行缩放或者放大的操作来增强数据样本的尺度信息。

- 缩放大样本；
- 放大小样本；

**随机裁剪**

对包含小目标的图像，在不改变目标位置的情况下，可以通过随机裁剪的方式得到过个不同的图像样本，以增强书记肚饿多样性。<u>此外，可以使用非矩形的裁剪方式，例如多边形裁剪，来更好地适应小目标的不规则形状。</u> 

**高级组合**

这块就和yolo中的Mosaic增强相似，有多张原始图像进行拼接而成。这样每张图就有更大概率包含小目标。

此外，我们还可以通过诸如 Copy-Paste 的办法将各类小目标充分的“复制-黏贴”，从而增加小目标的“曝光度”，提升他们被检测的概率。 

> **大图切分**

**Tiling**

`Tiling`是一种对大图进行切分的有效预处理操作，`Roboflow`平台可以演示。通过`tile`可以有效地让目标检测网络更好的聚焦在小物体上，同时允许我们保持所需的小输入分辨率，以便能够运行快速推断。不过需要注意的是，在推理时也理应保持输入的一致性。 

**SAHI**（了解一波集成到yolov5的）

Tiling 算是比较老旧的技术，目前笔者强烈推荐的还是`Slicing Aided Hyper Inference, SAHI`，即切片辅助超级推理，是一个专用于小目标检测的推理框架，理论上可以集成到任意的目标检测器上，无需进行任何微调。该方法目前已被多个成熟的目标检测框架和模型集成进去，如`YOLOv5`、`Detectron2`和`MMDetection`等。

> **损失函数**

**加权求和**

就是在对小目标检测的loss计算的时候，对其施加较大的权重，让网络更加关注这一部分。

**Stitcher**

![](./img/小目标图2.png)

`Stitcher`是早几年出的产物，其出自《`Stitcher: Feedback-driven Data Provider for Object Detection`》一文。作者通过统计分析观察到，小目标之所以检测性能很差是因为在训练时对损失的贡献很小（要么漏检要么漏标）。因此，文章中提出了一种基于训练时动态反馈的机制，即根据计算出来的损失，自动决定是否要进行图像拼接的操作。 

> **其他**

最后就是推荐一些具有代表性的小目标检测文章：

**2023**

- **TinyDet: Accurate Small Object Detection in Lightweight Generic Detectors**

![](./img/小目标图3.png)

- **YOLO-Drone: Airborne real-time detection of dense small targets from high-altitude perspective**

![](./img/小目标图4.png)

**2022**

- **Towards Large-Scale Small Object Detection: Survey and Benchmarks**

![](./img/小目标图5.png)

- **Small-Object Detection in Remote Sensing Images with End-to-End Edge-Enhanced GAN and Object Detector Network**

**2019**

- **Augmentation for small object detection**